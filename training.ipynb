{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying and Benchmarking a Shallow Neural Network for Ship Detection on Clustergate\n",
    "\n",
    "In this demo, we train a quantized aware model to detect ships from satellite imagery and later deploy it on the flight computer of Clustergate. \n",
    "The goal is to provide a simple demonstration on how to deploy machine learning on Clustergate and provide a benchmark on the performance of the Phoenix computer. \n",
    "\n",
    "With this project, we aim to explore techniques to increase inference speed and efficiency on the flight computer.\n",
    "\n",
    "### Preparing the Dataset\n",
    "Download the shipsnet.json from: https://www.kaggle.com/datasets/rhammell/ships-in-satellite-imagery\n",
    "\n",
    "### Training the model\n",
    "Run the block below to train the model. The training is performed in float32 first then performs finetuning for INT8 to improve the accuracy of the quantized model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training float32 model...\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.6131 - accuracy: 0.8019 - val_loss: 0.2781 - val_accuracy: 0.8900\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.1907 - accuracy: 0.9250 - val_loss: 0.1933 - val_accuracy: 0.9162\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.1651 - accuracy: 0.9388 - val_loss: 0.2742 - val_accuracy: 0.8863\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.1681 - accuracy: 0.9316 - val_loss: 0.1359 - val_accuracy: 0.9438\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 0.1378 - accuracy: 0.9472 - val_loss: 0.1177 - val_accuracy: 0.9550\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.1427 - accuracy: 0.9516 - val_loss: 0.1192 - val_accuracy: 0.9613\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.1304 - accuracy: 0.9559 - val_loss: 0.1083 - val_accuracy: 0.9650\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 4s 36ms/step - loss: 0.0876 - accuracy: 0.9709 - val_loss: 0.0969 - val_accuracy: 0.9725\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.0916 - accuracy: 0.9678 - val_loss: 0.0966 - val_accuracy: 0.9712\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 0.0818 - accuracy: 0.9734 - val_loss: 0.0971 - val_accuracy: 0.9725\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.0837 - accuracy: 0.9747 - val_loss: 0.1533 - val_accuracy: 0.9600\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 0.0526 - accuracy: 0.9819 - val_loss: 0.0948 - val_accuracy: 0.9762\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 5s 48ms/step - loss: 0.0661 - accuracy: 0.9803 - val_loss: 0.1170 - val_accuracy: 0.9737\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.0443 - accuracy: 0.9850 - val_loss: 0.1114 - val_accuracy: 0.9737\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.0358 - accuracy: 0.9856 - val_loss: 0.1119 - val_accuracy: 0.9737\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 0.0363 - accuracy: 0.9881 - val_loss: 0.0947 - val_accuracy: 0.9762\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 0.0373 - accuracy: 0.9875 - val_loss: 0.1379 - val_accuracy: 0.9712\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.0541 - accuracy: 0.9822 - val_loss: 0.1253 - val_accuracy: 0.9812\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.0437 - accuracy: 0.9844 - val_loss: 0.1098 - val_accuracy: 0.9800\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 0.0787 - accuracy: 0.9831 - val_loss: 0.1452 - val_accuracy: 0.9712\n",
      "Float32 model saved as shipsnet_float_new.h5\n",
      "25/25 [==============================] - 0s 5ms/step\n",
      "Float32 Accuracy: 0.9712\n",
      "Fine-tuning with quantization-aware training...\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 7s 61ms/step - loss: 0.2648 - accuracy: 0.7528 - val_loss: 0.2354 - val_accuracy: 0.7437\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 7s 66ms/step - loss: 0.0851 - accuracy: 0.9337 - val_loss: 0.0974 - val_accuracy: 0.9812\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 6s 64ms/step - loss: 0.0453 - accuracy: 0.9869 - val_loss: 0.1085 - val_accuracy: 0.9825\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0352 - accuracy: 0.9900 - val_loss: 0.0931 - val_accuracy: 0.9787\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.0219 - accuracy: 0.9944 - val_loss: 0.1199 - val_accuracy: 0.9825\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 6s 55ms/step - loss: 0.0227 - accuracy: 0.9934 - val_loss: 0.1896 - val_accuracy: 0.9625\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 7s 71ms/step - loss: 0.0243 - accuracy: 0.9931 - val_loss: 0.1023 - val_accuracy: 0.9762\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 9s 89ms/step - loss: 0.0200 - accuracy: 0.9947 - val_loss: 0.1568 - val_accuracy: 0.9787\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.0129 - accuracy: 0.9966 - val_loss: 0.1775 - val_accuracy: 0.9800\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0340 - accuracy: 0.9878 - val_loss: 0.2335 - val_accuracy: 0.9675\n",
      "Quantized Keras model saved as shipsnet_quantized_new.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mhamedazizbelkhiria/Documents/Dev/ships/lib/python3.11/site-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "I0000 00:00:1740345866.283539  314698 devices.cc:76] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "I0000 00:00:1740345866.284634  314698 single_machine.cc:361] Starting new session\n",
      "I0000 00:00:1740345866.286403  314698 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1740345866.286424  314698 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "I0000 00:00:1740345866.415053  314698 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1740345866.415096  314698 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "I0000 00:00:1740345866.446267  314698 devices.cc:76] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "I0000 00:00:1740345866.446344  314698 single_machine.cc:361] Starting new session\n",
      "I0000 00:00:1740345866.446852  314698 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1740345866.446867  314698 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "I0000 00:00:1740345866.515966  314698 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1740345866.515994  314698 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted to ONNX: shipsnet_new.onnx\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "# Load ShipsNet dataset from JSON\n",
    "def load_shipsnet(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    images = np.array(data['data']).reshape(-1, 80, 80, 3) / 255.0  # Normalize to [0, 1]\n",
    "    labels = np.array(data['labels'])\n",
    "    return images, labels\n",
    "\n",
    "# Build shallow CNN\n",
    "def create_shallow_cnn():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(80, 80, 3)),\n",
    "        tf.keras.layers.Conv2D(16, (3, 3), padding='same', name='conv1'),\n",
    "        tf.keras.layers.ReLU(name='relu1'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2), name='pool1'),\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), padding='same', name='conv2'),\n",
    "        tf.keras.layers.ReLU(name='relu2'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2), name='pool2'),\n",
    "        tf.keras.layers.Flatten(name='flatten'),\n",
    "        tf.keras.layers.Dense(64, name='dense1'),\n",
    "        tf.keras.layers.ReLU(name='relu3'),\n",
    "        tf.keras.layers.Dense(2, activation='softmax', name='output')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Main training function\n",
    "def main():\n",
    "    # Load dataset\n",
    "    json_path = 'shipsnet.json'  # Adjust path if needed\n",
    "    images, labels = load_shipsnet(json_path)\n",
    "\n",
    "    # Split dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, 2)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, 2)\n",
    "\n",
    "    # Create float32 model and train to get baseline\n",
    "    float_model = create_shallow_cnn()\n",
    "    float_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    print(\"Training float32 model...\")\n",
    "    float_model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
    "    float_model.save(\"shipsnet_float_new.h5\")\n",
    "    print(\"Float32 model saved as shipsnet_float_new.h5\")\n",
    "\n",
    "    # Evaluate float32 accuracy\n",
    "    preds = float_model.predict(X_test)\n",
    "    pred_labels = np.argmax(preds, axis=1)\n",
    "    y_test_labels = np.argmax(y_test, axis=1)\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    float_accuracy = accuracy_score(y_test_labels, pred_labels)\n",
    "    print(f\"Float32 Accuracy: {float_accuracy:.4f}\")\n",
    "\n",
    "    # Apply QAT\n",
    "    qat_model = tfmot.quantization.keras.quantize_model(float_model)\n",
    "    qat_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Fine-tune with quantization\n",
    "    print(\"Fine-tuning with quantization-aware training...\")\n",
    "    qat_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "    # Save quantized Keras model\n",
    "    qat_model.save(\"shipsnet_quantized_new.h5\")\n",
    "    print(\"Quantized Keras model saved as shipsnet_quantized_new.h5\")\n",
    "\n",
    "    # Export to ONNX\n",
    "    import tf2onnx\n",
    "    onnx_path = \"shipsnet_new.onnx\"\n",
    "    model_proto, _ = tf2onnx.convert.from_keras(\n",
    "        qat_model,\n",
    "        input_signature=[tf.TensorSpec([None, 80, 80, 3], tf.float32, name='input')],\n",
    "        opset=18,\n",
    "        output_path=onnx_path\n",
    "    )\n",
    "    print(f\"Converted to ONNX: {onnx_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory created: /output\n",
      "Loaded 20 test samples\n",
      "ONNX model loaded\n",
      "Ran inference on 20 images\n",
      "CSV saved to /output/inference_timings.csv\n",
      "Quantized Accuracy: 0.9000\n",
      "Average total inference time per image: 0.000709 seconds\n",
      "Total inference timings saved to /output/inference_timings.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import onnxruntime as ort\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "os.makedirs('./output', exist_ok=True)\n",
    "print(\"Output directory created: /output\")\n",
    "\n",
    "with open('shipsnet_20.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "X_test = np.array(data['data']).reshape(-1, 80, 80, 3) / 255.0  # Preprocess: Normalize to [0, 1]\n",
    "y_test = np.array(data['labels'])\n",
    "print(f\"Loaded {X_test.shape[0]} test samples\")\n",
    "\n",
    "session = ort.InferenceSession('shipsnet_new.onnx')\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name\n",
    "print(\"ONNX model loaded\")\n",
    "\n",
    "timings = []\n",
    "for i in range(X_test.shape[0]):\n",
    "    timing = {'image_id': i}\n",
    "    input_data = X_test[i:i+1].astype(np.float32)  # Float32 input\n",
    "    start = time.time()\n",
    "    outputs = session.run([output_name], {input_name: input_data})\n",
    "    timing['total_inference'] = time.time() - start\n",
    "    timings.append(timing)\n",
    "    pred_label = np.argmax(outputs[0][0])\n",
    "    if i == 0:\n",
    "        preds_labels = [pred_label]\n",
    "    else:\n",
    "        preds_labels.append(pred_label)\n",
    "print(f\"Ran inference on {len(timings)} images\")\n",
    "\n",
    "quantized_accuracy = accuracy_score(y_test, preds_labels)\n",
    "df = pd.DataFrame(timings)\n",
    "df = df[['image_id', 'total_inference']]\n",
    "df.to_csv('./output/inference_timings.csv', index=False)\n",
    "print(\"CSV saved to /output/inference_timings.csv\")\n",
    "\n",
    "print(f\"Quantized Accuracy: {quantized_accuracy:.4f}\")\n",
    "print(f\"Average total inference time per image: {df['total_inference'].mean():.6f} seconds\")\n",
    "print(\"Total inference timings saved to /output/inference_timings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ships",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
